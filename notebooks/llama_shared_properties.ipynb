{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ec9daa-14ac-441c-b4b1-92eb871b053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e12baa-9bba-4ecc-8714-17f3b9e87cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82f6cb90-e28e-4af0-b4b5-d313a9dd080e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "mcrae_train25_file = \"/home/amitgajbhiye/cardiff_work/llm_embeddings/data/mcrae/most_frequent_properties/train25.tsv\"\n",
    "train_df = pd.read_csv(mcrae_train25_file, sep=\"\\t\", names=[\"concept\", \"property\", \"label\"])\n",
    "\n",
    "positive_train_df = train_df[train_df[\"label\"] == 1]\n",
    "\n",
    "positive_train_df.sort_values(by=[\"property\"], inplace=True)\n",
    "positive_train_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print (\"positive_train_df\")\n",
    "print (positive_train_df)\n",
    "\n",
    "uniq_props = positive_train_df[\"property\"].unique()\n",
    "\n",
    "print (\"uniq_props\")\n",
    "print (uniq_props)\n",
    "\n",
    "num_concepts = 5\n",
    "\n",
    "all_concepts_list = []\n",
    "\n",
    "for prop in uniq_props:\n",
    "    concepts = positive_train_df[positive_train_df[\"property\"] == prop][\"concept\"].to_list()[:num_concepts]\n",
    "    concepts_list = \", \".join(concepts)\n",
    "    \n",
    "    all_concepts_list.append((concepts_list, prop))\n",
    "    \n",
    "    print (concepts_list)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095827a8-0dfb-40be-97e2-93c010e4ab17",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "prompt = f\"Enumerate the five most salient properties shared by the following concepts - <CONCEPT_LIST>. Generate only the numbered list of properties.\"\n",
    "\n",
    "prompt_list = [(prompt.replace(\"<CONCEPT_LIST>\", concept_list), original_property) for concept_list, original_property in all_concepts_list]\n",
    "\n",
    "print (prompt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80893b1-68b8-492a-8c10-f9f3349e9f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e142f61c-4637-4a4a-a870-c91cc817947d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce5da94335f43048cc498b272361df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu and disk.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c3aacc2-63af-44ea-9cd9-8f76e0ec795a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_types: 10\n",
      "sample_types: ['event', 'time', 'accident', 'person', 'place']\n"
     ]
    }
   ],
   "source": [
    "input_file = \"/home/amitgajbhiye/cardiff_work/llm_embeddings/data/ufet/clean_types.txt\"\n",
    "# df = pd.read_csv(input_file, sep=\"\\t\", names=[\"type\"])\n",
    "\n",
    "with open(input_file, \"r\") as f:\n",
    "    types = f.readlines()\n",
    "\n",
    "types = [type.strip(\"\\n\").strip() for type in types][0:10]\n",
    "print(f\"num_types: {len(types)}\")\n",
    "print(f\"sample_types: {random.sample(types, 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3e62432-2a86-41f4-b259-74441b41b57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['List the five most salient properties of person. Generate only the numbered list of properties.', 'List the five most salient properties of group. Generate only the numbered list of properties.', 'List the five most salient properties of organization. Generate only the numbered list of properties.', 'List the five most salient properties of location. Generate only the numbered list of properties.', 'List the five most salient properties of entity. Generate only the numbered list of properties.', 'List the five most salient properties of time. Generate only the numbered list of properties.', 'List the five most salient properties of object. Generate only the numbered list of properties.', 'List the five most salient properties of event. Generate only the numbered list of properties.', 'List the five most salient properties of place. Generate only the numbered list of properties.', 'List the five most salient properties of accident. Generate only the numbered list of properties.']\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"List the five most salient properties of <CONCEPT>. Generate only the numbered list of properties.\"\n",
    "prompts = [prompt.replace('<CONCEPT>', type) for type in types][0:150]\n",
    "\n",
    "print (prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa7444f-92cb-4aaf-b945-8b17f0aca62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List the five most salient properties of person. Generate only the numbered list of properties.\n",
      "\n",
      "1. Consciousness\n",
      "2. Reason\n",
      "3. Emotion\n",
      "4. Morality\n",
      "5. Sociality\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "response_list = []\n",
    "\n",
    "file_name = f'generated_properties_{model.replace(\"/\", \"_\").replace(\"-\", \"_\")}.txt'\n",
    "\n",
    "with open (file_name, 'w') as out_file:\n",
    "    for prompt in prompts:\n",
    "        \n",
    "        sequences = pipeline(\n",
    "            prompt,\n",
    "            do_sample=True,\n",
    "            top_k=1,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            max_length=350,\n",
    "          )\n",
    "        \n",
    "        for seq in sequences:\n",
    "            response_list.append(f\"{seq['generated_text']}\\n\\n\")\n",
    "            print(f\"{seq['generated_text']}\")\n",
    "\n",
    "            out_file.write(f'{seq[\"generated_text\"]}\\n')\n",
    "            \n",
    "            print(\"===================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1744fda9-2d6f-4199-a29c-4d2f70b56865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac45e3a-2fa2-4ca0-88c5-0dbb2defa15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd8c5f-e917-43ce-aea5-d12e2d449717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41234650-91a5-4ab9-9e43-e02d144af7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3619a8-e756-482f-9c6f-308693c085cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84df863d-2d0e-41c8-97b9-ae95e649a537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5babd2-a2d1-43e6-801c-c9dbd654e6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfb0f78-a0bd-421d-bcc8-0072ea1a3aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
